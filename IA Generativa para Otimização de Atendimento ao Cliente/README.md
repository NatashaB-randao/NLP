# üöÄ IA Generativa para Otimiza√ß√£o de Atendimento ao Cliente

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg) ![Libraries](https://img.shields.io/badge/Libraries-Pandas%20%7C%20Transformers%20%7C%20NLTK-orange.svg) ![License](https://img.shields.io/badge/License-MIT-green.svg)

### Um projeto de portf√≥lio de Natasha Brand√£o

Este reposit√≥rio cont√©m o c√≥digo e a documenta√ß√£o de um prot√≥tipo de ponta a ponta que utiliza Processamento de Linguagem Natural (NLP) e um Modelo de Linguagem Grande (LLM) para analisar e gerar respostas para tweets de atendimento ao cliente.

---

## üéØ Vis√£o Geral do Projeto

No cen√°rio digital atual, empresas lidam com um volume massivo de intera√ß√µes de clientes em redes sociais. Este projeto aborda esse desafio, desenvolvendo um sistema de IA que classifica a inten√ß√£o e o sentimento de um tweet e, em seguida, gera uma resposta contextual e apropriada, demonstrando um fluxo de trabalho completo de Ci√™ncia de Dados e IA.

## ‚ú® Principais Funcionalidades

*   **Classifica√ß√£o Autom√°tica de Inten√ß√£o:** Identifica se um tweet de cliente √© uma `reclama√ß√£o`, `d√∫vida`, `elogio` ou `outro`.
*   **An√°lise de Sentimento:** Classifica o tom emocional de cada tweet como `positivo`, `negativo` ou `neutro` usando NLTK (VADER).
*   **Gera√ß√£o Contextual de Respostas:** Utiliza o modelo `gpt2` da Hugging Face com a t√©cnica de "One-Shot Prompting" para gerar respostas coerentes.


---

## üõ†Ô∏è Stack de Tecnologias

| Biblioteca / Ferramenta      | Aplica√ß√£o no Projeto                                                                                                                                                                                            |
| :--------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Pandas & NumPy**           | Utilizados para a manipula√ß√£o, limpeza, filtragem e estrutura√ß√£o dos dados. A base de toda a an√°lise.                                                                                                             |
| **Matplotlib & Seaborn**     | Empregados para a cria√ß√£o de visualiza√ß√µes de dados para extrair e apresentar insights durante a An√°lise Explorat√≥ria.                                                                                            |
| **NLTK (VADER)**             | Usado para a an√°lise de sentimentos, sendo uma ferramenta especializada em textos de redes sociais.                                                                                                                 |
| **Transformers (Hugging Face)** | O cora√ß√£o da modelagem. Utilizado para carregar e executar o LLM `gpt2`, gerenciando o processo de tokeniza√ß√£o e gera√ß√£o de texto.                                                                                |
| **PyTorch / TensorFlow**     | O motor computacional que roda "por baixo dos panos" da biblioteca `transformers`, realizando os c√°lculos em tensores e otimizando para GPU.                                                                       |
| **Jupyter/Kaggle Notebooks** | O ambiente de desenvolvimento interativo onde todo o projeto foi prototipado e documentado.                                                                                                                       |

---

## ‚öôÔ∏è Como Funciona: A Metodologia

O projeto foi estruturado em um pipeline l√≥gico de ci√™ncia de dados, **combinando t√©cnicas de NLP cl√°ssico para an√°lise e um LLM para gera√ß√£o**:

1.  **An√°lise Explorat√≥ria de Dados (EDA):** A an√°lise inicial do dataset de ~3 milh√µes de tweets revelou que a grande maioria dos dados estava concentrada em 2017. Isso levou √† decis√£o estrat√©gica de filtrar o dataset para focar neste per√≠odo.

2.  **Pr√©-processamento e Limpeza (NLP):** O texto dos tweets foi limpo, removendo ru√≠dos como URLs, men√ß√µes de usu√°rio, hashtags e stopwords para preparar os dados para a an√°lise.

3.  **Engenharia de Features (NLP):** **Nesta fase, t√©cnicas de NLP foram usadas para entender e estruturar o texto, criando duas features cruciais:**
    *   `tipo_refinado`: Classifica a inten√ß√£o do cliente (reclama√ß√£o, d√∫vida, etc.) usando regras baseadas em **correspond√™ncia de palavras-chave**.
    *   `sentimento`: Classifica o tom do tweet (positivo, negativo, neutro) usando o analisador **VADER**, um modelo baseado em l√©xico.

4.  **Modelagem e Gera√ß√£o de Respostas (LLM):** **Aqui, um Modelo de Linguagem Grande foi usado para criar novo texto com base no contexto:**
    *   Ap√≥s experimenta√ß√£o, o modelo **`gpt2`**, um LLM da fam√≠lia Transformer, foi escolhido por sua flexibilidade.
    *   Foi implementada uma fun√ß√£o de gera√ß√£o com um prompt de **"One-Shot"**, que fornece um exemplo de alta qualidade para guiar o modelo, resultando em respostas mais coerentes e no tom correto.

---

## üöÄ Como Executar o Projeto Localmente

Para executar o dashboard interativo em sua m√°quina, siga os passos abaixo.

**Pr√©-requisitos:**
*   Python 3.9+
*   `pip` e `venv`

### 1. Clone o reposit√≥rio:
```bash
git clone https://github.com/seu-usuario/nome-do-repositorio.git
cd nome-do-repositorio
```


### 2. Crie e ative um ambiente virtual:

**Para MacOS/Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Para Windows:**
```bash
python -m venv venv
.\venv\Scripts\activate
```

### 3. Instale as depend√™ncias:
*(Nota: Crie este arquivo primeiro executando `pip freeze > requirements.txt` no seu ambiente)*

```bash
pip install -r requirements.txt
```


## üèÜ Desafios e Aprendizados

O maior desafio durante a modelagem foi a **engenharia de prompt**. A tentativa inicial com o modelo `microsoft/DialoGPT` e prompts instrucionais n√£o gerou bons resultados, pois o modelo √© muito especializado em continuar di√°logos e n√£o em seguir instru√ß√µes.

A principal li√ß√£o aprendida foi que a **escolha do modelo e a t√©cnica de prompt est√£o intrinsecamente ligadas**. A mudan√ßa para o `gpt2` (um modelo de prop√≥sito geral) combinada com um prompt de "One-Shot" (que mostra um exemplo) foi a chave para o sucesso do projeto.

## üìà Melhorias Futuras

- **Evoluir a Classifica√ß√£o de Inten√ß√£o**: Substituir o classificador por regras por um modelo de Machine Learning treinado (e.g., BERT) para maior precis√£o.

- **Personalizar o Tom com Fine-tuning**: Realizar o ajuste fino do `gpt2` com dados espec√≠ficos de uma marca para que ele aprenda seu tom de voz.

- **Integrar Modelos Maiores (via API)**: Testar a integra√ß√£o com APIs como GPT-4 ou Gemini para comparar a qualidade das respostas.

- **Desenvolvimento de um Dashboard Interativo**: Empacotar a solu√ß√£o em um dashboard com Streamlit para demonstra√ß√£o.

- **An√°lise de Custo-Benef√≠cio**: Em um contexto de neg√≥cio, analisar o impacto da automa√ß√£o no Tempo M√©dio de Resposta (TMR) e o Retorno Sobre o Investimento (ROI).

## üë§ Autor

**Natasha Brand√£o**
- **[LinkedIn](https://www.linkedin.com/in/natasha-brand%C3%A3o/)**
- **[GitHub](https://github.com/NatashaB-randao)**