{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8841,"sourceType":"datasetVersion","datasetId":4133}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üöÄ Projeto de Portf√≥lio: Otimiza√ß√£o de Atendimento ao Cliente com IA Generativa\n\n*   **Autor:** Natasha Brand√£o\n*   **Data:** 07/08/2025\n\n---\n\n### 1. Contexto do Problema\n\nNo cen√°rio digital atual, empresas de grande porte lidam com um volume massivo de intera√ß√µes de clientes em redes sociais. Analisar e responder a cada tweet de forma eficiente √© um desafio log√≠stico e de custo. Respostas lentas ou inadequadas podem levar √† insatisfa√ß√£o do cliente, enquanto a an√°lise manual de milhares de mensagens √© impratic√°vel.\n\n### 2. Objetivo do Projeto\n\nEste projeto tem como objetivo desenvolver um prot√≥tipo de ponta a ponta de um sistema de Intelig√™ncia Artificial para otimizar o atendimento ao cliente. A solu√ß√£o ir√°:\n\n1.  **Analisar e classificar** automaticamente os tweets dos clientes em categorias (reclama√ß√£o, elogio, d√∫vida).\n2.  **Detectar o sentimento** (positivo, negativo, neutro) de cada mensagem.\n3.  **Gerar respostas contextuais e adequadas** usando um modelo de linguagem avan√ßado (LLM).\n4.  **(Etapa Futura) Apresentar os resultados** de forma interativa atrav√©s de um dashboard.\n\n### ‚úÖ Habilidades e Tecnologias Demonstradas\n\nEste projeto serve como uma demonstra√ß√£o pr√°tica de um fluxo de trabalho de ponta a ponta em Ci√™ncia de Dados e IA, cobrindo as seguintes compet√™ncias t√©cnicas e anal√≠ticas:\n\n*   **Engenharia de Features e An√°lise de Dados:** An√°lise explorat√≥ria (EDA), limpeza de dados textuais, e cria√ß√£o de features relevantes (e.g., tipo de mensagem, sentimento) a partir de dados n√£o estruturados.\n*   **Processamento de Linguagem Natural (NLP):** T√©cnicas de pr√©-processamento, an√°lise de sentimento com NLTK (VADER) e modelagem de t√≥picos impl√≠cita atrav√©s da gera√ß√£o de respostas.\n*   **IA Generativa e LLMs:** Utiliza√ß√£o da biblioteca `transformers` (Hugging Face) para implementar e controlar um Large Language Model (como o GPT-2) na gera√ß√£o de texto contextual.\n*   **Modelagem de Machine Learning:** Aplica√ß√£o de modelos pr√©-treinados para tarefas de NLP e prototipagem de uma solu√ß√£o de IA.\n*   **Visualiza√ß√£o de Dados e BI:** Cria√ß√£o de visualiza√ß√µes para extrair insights e (na etapa final) desenvolvimento de um dashboard interativo para apresentar os resultados de forma clara.\n*   **Pensamento Estrat√©gico:** Tradu√ß√£o de um problema de neg√≥cio (otimiza√ß√£o de atendimento) em um plano de projeto t√©cnico, executado de forma sequencial e l√≥gica.\n\n### Dataset\n*   **Fonte:** [Customer Support on Twitter](https://www.kaggle.com/datasets/thoughtvector/customer-support-on-twitter)\n*   **Descri√ß√£o:** Um grande dataset do Kaggle contendo quase 3 milh√µes de tweets de e para grandes marcas.","metadata":{}},{"cell_type":"code","source":"# --- Configura√ß√£o do Ambiente e Bibliotecas Essenciais ---\n\n# An√°lise de Dados e Manipula√ß√£o\nimport pandas as pd\nimport numpy as np\n\n# Visualiza√ß√£o de Dados\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Utilit√°rios do Sistema\nimport os\n\n# Configura√ß√µes de Visualiza√ß√£o (opcional, para deixar os gr√°ficos mais bonitos)\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\n\n# --- Verifica√ß√£o Inicial dos Arquivos ---\n# Este loop inicial nos ajuda a confirmar os caminhos dos arquivos de dados dispon√≠veis.\nprint(\"Arquivos de dados dispon√≠veis:\")\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-08-14T15:00:15.590618Z","iopub.execute_input":"2025-08-14T15:00:15.590961Z","iopub.status.idle":"2025-08-14T15:00:16.864578Z","shell.execute_reply.started":"2025-08-14T15:00:15.590931Z","shell.execute_reply":"2025-08-14T15:00:16.863694Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Parte 1: An√°lise Explorat√≥ria e Engenharia de Features\n\n## üß† Objetivo da An√°lise Explorat√≥ria de Dados (EDA)\n\nAntes de construir qualquer modelo, precisamos entender profundamente nossos dados. O objetivo desta primeira fase √© responder √†s seguintes perguntas-chave:\n\n*   Qual √© o volume total de intera√ß√µes no dataset?\n*   Como as conversas entre clientes e empresas est√£o estruturadas?\n*   Quais s√£o os temas e palavras-chave mais recorrentes nas mensagens?\n*   √â poss√≠vel identificar automaticamente se um tweet √© uma pergunta, reclama√ß√£o ou elogio?\n*   Como o volume de atendimentos se distribui ao longo do tempo? Existe alguma sazonalidade?\n\n---\n### üõ†Ô∏è Etapas do EDA\n\n#### 1. Carregando os Dados","metadata":{}},{"cell_type":"code","source":"# Importando pandas para manipula√ß√£o de dados\nimport pandas as pd\n\n# Carregando o conjunto de dados principal em um DataFrame do pandas.\n# O arquivo est√° no formato CSV (Comma-Separated Values).\ndf = pd.read_csv('/kaggle/input/customer-support-on-twitter/twcs/twcs.csv')\n\n# Exibindo as primeiras 5 linhas para uma inspe√ß√£o inicial da estrutura e do conte√∫do.\n# Isso nos ajuda a ter uma primeira impress√£o dos dados com os quais estamos trabalhando.\ndf.head()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-08-14T15:00:16.866285Z","iopub.execute_input":"2025-08-14T15:00:16.866656Z","iopub.status.idle":"2025-08-14T15:00:39.054246Z","shell.execute_reply.started":"2025-08-14T15:00:16.866633Z","shell.execute_reply":"2025-08-14T15:00:39.053504Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. An√°lise Estrutural e Valida√ß√£o dos Dados\n\nNesta etapa, realizamos uma verifica√ß√£o fundamental para entender as dimens√µes, os tipos de dados e a integridade do nosso DataFrame. Isso √© crucial para planejar as etapas de limpeza e pr√©-processamento.\n\nVamos verificar:\n*   **Dimens√µes:** N√∫mero de linhas e colunas.\n*   **Tipos de Dados (Dtypes):** Se as colunas foram lidas corretamente (n√∫meros, texto, data, etc.).\n*   **Valores Nulos:** A quantidade de dados ausentes em cada coluna.","metadata":{}},{"cell_type":"code","source":"# --- Verifica√ß√£o T√©cnica do DataFrame ---\n\n# Um resumo completo da estrutura, incluindo tipos de dados e uso de mem√≥ria.\nprint(\"--- Informa√ß√µes Gerais do DataFrame (df.info()) ---\")\ndf.info()\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n# Contagem de valores nulos para cada coluna.\nprint(\"--- Contagem de Valores Nulos por Coluna ---\")\nprint(df.isnull().sum())","metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-08-14T15:00:39.054925Z","iopub.execute_input":"2025-08-14T15:00:39.055214Z","iopub.status.idle":"2025-08-14T15:00:39.758148Z","shell.execute_reply.started":"2025-08-14T15:00:39.055195Z","shell.execute_reply":"2025-08-14T15:00:39.757289Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Principais Observa√ß√µes:\n\n1.  **Volume Massivo:** O dataset cont√©m aproximadamente **2.8 milh√µes de tweets**, confirmando a necessidade de uma solu√ß√£o automatizada.\n2.  **Datas como Texto:** A coluna `created_at` foi lida como `object` (texto). Precisaremos convert√™-la para um formato de data (`datetime`) para realizar an√°lises temporais.\n3.  **Valores Nulos Estrat√©gicos:** As colunas `response_tweet_id` e `in_response_to_tweet_id` possuem um grande n√∫mero de valores nulos. Isso √© uma informa√ß√£o valiosa: um tweet com `in_response_to_tweet_id` nulo provavelmente √© o **in√≠cio de uma conversa**, ou seja, o primeiro contato de um cliente.","metadata":{}},{"cell_type":"markdown","source":"### 3. Reconstruindo o Fio da Conversa\n\nO DataFrame apresenta os tweets de forma \"plana\", mas eles fazem parte de conversas encadeadas. Para entender a din√¢mica do atendimento, √© essencial reconstruir um exemplo de intera√ß√£o `Cliente -> Empresa`. O c√≥digo abaixo faz exatamente isso.","metadata":{}},{"cell_type":"code","source":"# --- L√≥gica para Exibir uma Conversa de Exemplo ---\n\n# 1. Identificar os autores que s√£o empresas (aqueles que enviam tweets \"outbound\").\n# A coluna 'inbound' nos diz se o tweet foi direcionado √† empresa (True) ou enviado pela empresa (False).\nempresas = df[df['inbound'] == False]['author_id'].unique()\n\n# 2. Selecionar uma amostra aleat√≥ria de um tweet que seja de um cliente (N√ÉO √© de uma empresa) e que tenha recebido uma resposta.\ntweet_do_cliente = df[(~df['author_id'].isin(empresas)) & (df['response_tweet_id'].notna())].sample(1)\n\n# 3. Extrair os IDs do tweet do cliente e da resposta da empresa.\nid_tweet_cliente = tweet_do_cliente['tweet_id'].values[0]\nid_resposta_empresa = tweet_do_cliente['response_tweet_id'].values[0]\n\n# 4. Localizar o texto da resposta da empresa usando o ID obtido.\n# √â necess√°rio converter o ID da resposta para inteiro (int) para corresponder ao tipo de 'tweet_id'.\ntexto_cliente = tweet_do_cliente['text'].values[0]\nresposta_empresa = df[df['tweet_id'] == int(id_resposta_empresa)]\n\n# 5. Exibir a conversa reconstru√≠da.\nprint(f\"TWEET DO CLIENTE: {texto_cliente}\")\n\nif not resposta_empresa.empty:\n    print(f\"RESPOSTA DA EMPRESA: {resposta_empresa['text'].values[0]}\")\nelse:\n    print(\"RESPOSTA DA EMPRESA: N√£o encontrada.\")\n","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-08-14T15:00:39.758928Z","iopub.execute_input":"2025-08-14T15:00:39.759194Z","iopub.status.idle":"2025-08-14T15:00:40.562071Z","shell.execute_reply.started":"2025-08-14T15:00:39.759174Z","shell.execute_reply":"2025-08-14T15:00:40.561343Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Parte 2: Pr√©-processamento e Limpeza dos Dados\n\nCom os insights da EDA, agora preparamos os dados para a modelagem. Isso envolve duas etapas principais: filtrar o dataset para o per√≠odo de maior relev√¢ncia e limpar o texto dos tweets para remover ru√≠dos.\n\n### 1. Filtragem Temporal e Limpeza de Texto","metadata":{}},{"cell_type":"code","source":"# --- ETAPA DE PREPARA√á√ÉO ---\n\n# Importando as bibliotecas necess√°rias para esta se√ß√£o.\nimport pandas as pd\nimport re  # Biblioteca para express√µes regulares, essencial para a limpeza de texto.\nfrom nltk.corpus import stopwords\nimport nltk\n\n# 1. Converter a coluna 'created_at' para o formato de data.\n#    Especificamos o 'format' para melhorar a performance e remover avisos.\n#    O formato corresponde exatamente √† estrutura da data no CSV (Ex: 'Tue Oct 31 22:10:47 +0000 2017')\ndf['created_at'] = pd.to_datetime(df['created_at'], format='%a %b %d %H:%M:%S %z %Y', errors='coerce')\n\n# 2. Filtrar o DataFrame para manter apenas os dados a partir de 2017, per√≠odo de maior atividade.\ndf_filtered = df[df['created_at'].dt.year >= 2017].copy()\n\n# 3. Baixar a lista de stopwords (se ainda n√£o tiver sido baixada nesta sess√£o)\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\n\n# 4. Definir a fun√ß√£o para limpar o texto dos tweets.\n#    Esta fun√ß√£o ir√° remover elementos que n√£o agregam valor sem√¢ntico, como URLs, men√ß√µes e stopwords.\ndef clean_text(text):\n    text = str(text).lower()\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text) # Remove URLs\n    text = re.sub(r'@\\w+', '', text) # Remove men√ß√µes (@usuario)\n    text = re.sub(r'#', '', text) # Remove o s√≠mbolo de hashtag\n    text = re.sub(r'[^a-z\\s]', '', text) # Remove pontua√ß√µes e n√∫meros\n    text = ' '.join([word for word in text.split() if word not in stop_words]) # Remove 'stopwords'\n    return text\n\n# 5. Aplicar a fun√ß√£o de limpeza na coluna de texto para criar a coluna 'clean_text'.\ndf_filtered['clean_text'] = df_filtered['text'].apply(clean_text)\n\n# 6. Exibir uma amostra do resultado para validar a limpeza.\nprint(\"\\n--- Resultado da Limpeza ---\")\nprint(df_filtered[['text', 'clean_text']].head())","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-08-14T15:00:40.564641Z","iopub.execute_input":"2025-08-14T15:00:40.564926Z","iopub.status.idle":"2025-08-14T15:01:32.531917Z","shell.execute_reply.started":"2025-08-14T15:00:40.564902Z","shell.execute_reply":"2025-08-14T15:01:32.530963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. An√°lise do Comprimento das Mensagens\n\nUma an√°lise r√°pida do comprimento dos tweets nos ajuda a entender a natureza das intera√ß√µes. S√£o mensagens curtas e diretas ou longas e detalhadas? Isso pode nos dar pistas sobre a complexidade dos problemas dos clientes.","metadata":{}},{"cell_type":"code","source":"# --- An√°lise do Comprimento dos Tweets ---\n\n# 1. Criar uma nova coluna 'comprimento_texto' no DataFrame original 'df'.\n#    Usamos o DataFrame original para ter uma vis√£o completa, antes de qualquer filtragem.\ndf['comprimento_texto'] = df['text'].str.len()\n\n# 2. Criar um histograma para visualizar a distribui√ß√£o dos comprimentos.\n#    O histograma agrupa os tweets por faixas de comprimento e mostra a frequ√™ncia de cada faixa.\nplt.figure(figsize=(14, 7))\nsns.histplot(df['comprimento_texto'], bins=50, kde=True, color='skyblue')\nplt.title('Distribui√ß√£o do Comprimento dos Tweets (em caracteres)', fontsize=16)\nplt.xlabel('Comprimento do Texto (Caracteres)', fontsize=12)\nplt.ylabel('Frequ√™ncia (Quantidade de Tweets)', fontsize=12)\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-08-14T15:01:32.532775Z","iopub.execute_input":"2025-08-14T15:01:32.533029Z","iopub.status.idle":"2025-08-14T15:01:46.616799Z","shell.execute_reply.started":"2025-08-14T15:01:32.533010Z","shell.execute_reply":"2025-08-14T15:01:46.615973Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Insights:\n\n*   **Pico em ~140 Caracteres:** A grande maioria dos tweets se concentra em torno de 100 a 140 caracteres. Isso √© consistente com o limite hist√≥rico de 140 caracteres do Twitter, indicando que o dataset foi coletado majoritariamente nesse per√≠odo.\n*   **Cauda Longa √† Direita:** Existe uma pequena quantidade de tweets mais longos, provavelmente coletados ap√≥s a mudan√ßa do Twitter para 280 caracteres.\n\nEsta an√°lise confirma que estamos lidando com textos curtos e diretos, t√≠picos de redes sociais, o que guiar√° a escolha das nossas t√©cnicas de NLP.","metadata":{}},{"cell_type":"markdown","source":"### 3. An√°lise da Distribui√ß√£o por Ano\n\nSeguindo a hip√≥tese de que os dados podem n√£o ter sido coletados de forma cont√≠nua, vamos primeiro investigar o volume de tweets em cada ano. Esta an√°lise macro nos dar√° uma vis√£o clara da relev√¢ncia de cada per√≠odo e se existem lacunas na coleta de dados.","metadata":{}},{"cell_type":"code","source":"# --- An√°lise da Contagem de Tweets por Ano ---\n\n# 1. Garantir que a coluna 'created_at' est√° no formato de data.\ndf['created_at'] = pd.to_datetime(df['created_at'], format='%a %b %d %H:%M:%S %z %Y', errors='coerce')\n\n# 2. Extrair o ano de cada tweet para uma nova coluna.\ndf['year'] = df['created_at'].dt.year\n\n# 3. Contar o n√∫mero de tweets para cada ano e ordenar os resultados.\ntweets_por_ano = df['year'].value_counts().sort_index()\n\n# 4. Exibir os resultados em um formato claro.\nprint(\"--- Contagem de Tweets por Ano ---\")\n\n# Formata a coluna para ser um n√∫mero inteiro com separador de v√≠rgula\ntabela_formatada = tweets_por_ano.to_frame(name='Quantidade de Tweets')\ntabela_formatada['Quantidade de Tweets'] = tabela_formatada['Quantidade de Tweets'].map('{:,.0f}'.format)\n\nprint(tabela_formatada.to_markdown())\n\n# 5. Criar um gr√°fico de linha.\nplt.figure(figsize=(14, 8))\nplt.plot(tweets_por_ano.index, tweets_por_ano.values, marker='o', linestyle='-', color='teal')\nplt.title('Crescimento Exponencial de Tweets no Dataset (Escala Logar√≠tmica)', fontsize=16)\nplt.xlabel('Ano', fontsize=12)\nplt.ylabel('Quantidade de Tweets (Escala Log)', fontsize=12)\n\n# 6. Mudar a escala do eixo Y para logar√≠tmica para visualizar melhor os valores baixos.\nplt.yscale('log')\n\nplt.grid(True, which=\"both\", ls=\"--\")\n\n# 7. Adicionar os r√≥tulos de dados (data labels) em cada ponto do gr√°fico.\n#    Este loop percorre cada ano e sua respectiva contagem de tweets.\nfor ano, quantidade in tweets_por_ano.items():\n    # O comando 'plt.text' posiciona um texto nas coordenadas (x, y)\n    # Adicionamos um pequeno deslocamento vertical para o texto n√£o sobrepor o ponto.\n    plt.text(ano, quantidade * 1.1, f'{quantidade:,.0f}', ha='center', va='bottom', fontsize=9)\n    # '{:,.0f}' formata o n√∫mero com v√≠rgulas e sem casas decimais.\n\nplt.show()","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-08-14T15:01:46.618017Z","iopub.execute_input":"2025-08-14T15:01:46.618425Z","iopub.status.idle":"2025-08-14T15:01:47.578086Z","shell.execute_reply.started":"2025-08-14T15:01:46.618397Z","shell.execute_reply":"2025-08-14T15:01:47.577080Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4. An√°lise Detalhada da S√©rie Temporal (Di√°ria)\n\nA an√°lise anual confirmou de forma conclusiva que **a atividade do dataset se concentra quase que inteiramente em 2017**. Agora, vamos aplicar um \"zoom\" nesse per√≠odo, plotando o volume de tweets em uma base di√°ria. Isso nos permitir√° observar flutua√ß√µes e padr√µes de curto prazo com mais clareza.","metadata":{}},{"cell_type":"code","source":"# --- An√°lise da S√©rie Temporal de Tweets (Di√°ria) ---\n\n# 1. Agrupar a contagem de tweets por dia.\n#    O m√©todo 'resample('D')' √© uma forma poderosa do pandas para reagrupar dados de s√©ries temporais.\ntweets_por_dia = df.set_index('created_at')['tweet_id'].resample('D').count()\n\n# 2. Gerar um gr√°fico de linha para visualizar a tend√™ncia di√°ria.\nplt.figure(figsize=(16, 7))\ntweets_por_dia.plot(color='c')\nplt.title('Volume de Tweets por Dia ao Longo do Tempo', fontsize=16)\nplt.xlabel('Data', fontsize=12)\nplt.ylabel('Quantidade de Tweets', fontsize=12)\nplt.grid(True)\nplt.xlim(pd.Timestamp('2017-01-01'), pd.Timestamp('2017-12-31')) # Adicionando um zoom no gr√°fico\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T15:01:47.579172Z","iopub.execute_input":"2025-08-14T15:01:47.579478Z","iopub.status.idle":"2025-08-14T15:01:50.187744Z","shell.execute_reply.started":"2025-08-14T15:01:47.579447Z","shell.execute_reply":"2025-08-14T15:01:50.186947Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Insights da An√°lise Temporal\n\nAs duas an√°lises temporais, a anual e a di√°ria, nos fornecem uma vis√£o completa e poderosa sobre a distribui√ß√£o dos dados, revelando dois insights cr√≠ticos:\n\n1.  **Concentra√ß√£o Anual (Gr√°fico Logar√≠tmico):** A primeira an√°lise deixa claro que o dataset n√£o √© uma coleta cont√≠nua. Pelo contr√°rio, a atividade √© **massivamente concentrada no ano de 2017**. O uso da escala logar√≠tmica nos permite ver o crescimento nos anos anteriores, mas confirma que esses volumes s√£o insignificantes em compara√ß√£o com o salto exponencial no √∫ltimo ano.\n\n2.  **Intensifica√ß√£o da Coleta em 2017 (Gr√°fico Di√°rio):** Ao dar um \"zoom\" em 2017, descobrimos um padr√£o ainda mais espec√≠fico: a coleta de dados n√£o foi uniforme ao longo do ano. Houve uma **explos√£o dr√°stica no volume de tweets a partir de Outubro**, indicando que a grande maioria dos dados relevantes se concentra no **√∫ltimo trimestre (Q4) de 2017**.\n\n**Conclus√£o e Justificativa da A√ß√£o:**\nEstas descobertas validam de forma irrefut√°vel a nossa decis√£o, tomada na etapa de pr√©-processamento, de **filtrar o dataset para focar em 2017**. Esta a√ß√£o foi essencial para garantir que nossa an√°lise e futura modelagem sejam feitas sobre o conjunto de dados mais denso, consistente e relevante, otimizando o processamento e a qualidade dos resultados.\n\nCom a explora√ß√£o temporal conclu√≠da, podemos prosseguir com confian√ßa para a pr√≥xima fase: a cria√ß√£o de features a partir do nosso dataset limpo e focado.","metadata":{}},{"cell_type":"markdown","source":"# Parte 3: Engenharia de Features - Classifica√ß√£o de Inten√ß√£o\n\nCom um dataset limpo e filtrado, iniciamos a Engenharia de Features. Nosso objetivo √© transformar o texto n√£o estruturado dos tweets em uma **feature categ√≥rica e estruturada** que descreva a **inten√ß√£o** do cliente. Isso √© fundamental para que nossos modelos possam entender o contexto de cada mensagem.\n\n### 1. Classifica√ß√£o de Inten√ß√£o por Regras\n\nComo primeira abordagem, implementaremos um classificador simples baseado em regras e palavras-chave. Este m√©todo tem grandes vantagens para a prototipagem:\n\n*   **Rapidez:** √â computacionalmente muito eficiente.\n*   **Interpretabilidade:** As regras s√£o claras e f√°ceis de entender e ajustar.\n*   **Baseline:** Cria uma base de refer√™ncia s√≥lida para, futuramente, comparar com modelos de Machine Learning mais complexos.\n\nAs inten√ß√µes que buscaremos identificar s√£o: `RECLAMA√á√ÉO`, `D√öVIDA`, `ELOGIO` e `OUTRO`.","metadata":{}},{"cell_type":"code","source":"# --- Fun√ß√£o de Classifica√ß√£o e Aplica√ß√£o ---\n\n# 1. Defini√ß√£o da fun√ß√£o de classifica√ß√£o baseada em palavras-chave.\ndef classificar_tipo(texto):\n    \"\"\"Classifica um texto em 'reclamacao', 'duvida', 'elogio' ou 'outro'.\"\"\"\n    texto = str(texto).lower()\n    \n    # Listas de palavras-gatilho para cada categoria.\n    palavras_reclamacao = ['not working', 'problem', 'issue', 'broken', \"doesn't work\", 'worst', 'unacceptable', 'fail']\n    palavras_elogio = ['thanks', 'great', 'awesome', 'love', 'excellent', 'perfect', 'thank you', 'kudos']\n    \n    # A ordem da verifica√ß√£o √© importante para a l√≥gica.\n    if any(p in texto for p in palavras_reclamacao):\n        return 'reclamacao'\n    \n    # Assumimos que a presen√ßa de '?' indica uma d√∫vida.\n    elif '?' in texto:\n        return 'd√∫vida'\n        \n    elif any(p in texto for p in palavras_elogio):\n        return 'elogio'\n    \n    # Se nenhuma das condi√ß√µes anteriores for atendida, classificamos como 'outro'.\n    else:\n        return 'outro'\n\n# 2. Aplicar a fun√ß√£o na coluna de texto do nosso DataFrame FILTRADO e LIMPO.\n#    <<< CORRE√á√ÉO CR√çTICA: Usamos 'df_filtered' para manter a consist√™ncia do projeto.\ndf_filtered['tipo'] = df_filtered['text'].apply(classificar_tipo)\n\n# 3. Exibir a distribui√ß√£o das novas categorias.\nprint(\"--- Distribui√ß√£o das Inten√ß√µes dos Tweets ---\")\nprint(df_filtered['tipo'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T15:01:50.188815Z","iopub.execute_input":"2025-08-14T15:01:50.189187Z","iopub.status.idle":"2025-08-14T15:02:01.451810Z","shell.execute_reply.started":"2025-08-14T15:01:50.189156Z","shell.execute_reply":"2025-08-14T15:02:01.450858Z"},"_kg_hide-input":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Visualiza√ß√£o da Distribui√ß√£o das Inten√ß√µes ---\n\n# 1. Calcular a contagem de cada tipo.\ntipo_counts = df_filtered['tipo'].value_counts()\n\n# 2. Criar o gr√°fico de barras com Seaborn para um visual melhorado.\nplt.figure(figsize=(12, 7))\nax = sns.barplot(x=tipo_counts.index, y=tipo_counts.values, palette='mako')\nplt.title('Distribui√ß√£o dos Tipos de Mensagem (Inten√ß√£o)', fontsize=16)\nplt.xlabel('Tipo de Inten√ß√£o', fontsize=12)\nplt.ylabel('Quantidade de Tweets', fontsize=12)\n\n# 3. Adicionar r√≥tulos de dados (data labels) em cima de cada barra.\n#    Isso torna o gr√°fico muito mais f√°cil de ler.\nfor p in ax.patches:\n    ax.annotate(f'{int(p.get_height()):,}', # Formata o n√∫mero com v√≠rgulas\n                (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha='center', va='center', \n                xytext=(0, 9), \n                textcoords='offset points')\n\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T15:02:01.452809Z","iopub.execute_input":"2025-08-14T15:02:01.453098Z","iopub.status.idle":"2025-08-14T15:02:01.852168Z","shell.execute_reply.started":"2025-08-14T15:02:01.453067Z","shell.execute_reply":"2025-08-14T15:02:01.851273Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Insights da Distribui√ß√£o:\n\nO gr√°fico acima nos fornece a primeira vis√£o quantitativa sobre a natureza das intera√ß√µes no nosso dataset. Vemos uma distribui√ß√£o clara:\n\n1.  **Grande Volume de \"Outro\":** A categoria `outro` √© a maior, com mais de 1.6 milh√£o de tweets. Isso √© esperado, pois nosso classificador por regras √© conservador e s√≥ categoriza tweets que cont√™m palavras-chave muito espec√≠ficas. Este grupo representa uma vasta gama de intera√ß√µes que n√£o s√£o claramente reclama√ß√µes, d√∫vidas ou elogios.\n\n2.  **D√∫vidas s√£o Frequentes:** Com mais de 638 mil ocorr√™ncias, as `d√∫vidas` (identificadas pela presen√ßa de \"?\") s√£o a segunda categoria mais comum. Isso indica que uma grande parte do suporte ao cliente em redes sociais envolve esclarecer quest√µes dos usu√°rios.\n\n3.  **Elogios Superam Reclama√ß√µes:** Um insight interessante √© que o n√∫mero de `elogios` (317 mil) √© maior que o de `reclama√ß√µes` (242 mil). Isso sugere que os clientes tamb√©m usam o Twitter como um canal para expressar satisfa√ß√£o, e n√£o apenas para relatar problemas.\n\n**Implica√ß√£o Estrat√©gica:**\nA distribui√ß√£o nos mostra que, embora as reclama√ß√µes sejam um ponto cr√≠tico, um sistema de IA eficaz tamb√©m deve ser capaz de lidar com um grande volume de d√∫vidas e intera√ß√µes neutras, al√©m de saber como responder a um elogio para refor√ßar a lealdade do cliente.\n\nCom essa primeira classifica√ß√£o feita, o pr√≥ximo passo √© valid√°-la qualitativamente, observando amostras reais de cada categoria.```\n\n### Por que esta an√°lise √© valiosa:\n\n*   **Interpreta cada Categoria:** Ela n√£o apenas olha para o gr√°fico como um todo, mas tira uma conclus√£o para cada uma das barras.\n*   **Justifica os Resultados:** A an√°lise explica *por que* √© normal que a categoria `outro` seja a maior, demonstrando um entendimento do funcionamento do seu pr√≥prio classificador.\n*   **Extrai um Insight de Neg√≥cio:** A observa√ß√£o de que \"Elogios Superam Reclama√ß√µes\" √© um insight n√£o-trivial que pode ser valioso para uma equipe de marketing ou de produto.\n*   **Cria uma Transi√ß√£o L√≥gica:** A √∫ltima frase j√° prepara o terreno para a pr√≥xima etapa que voc√™ tem no seu notebook (a valida√ß√£o por amostragem), criando um fluxo narrativo perfeito.","metadata":{}},{"cell_type":"markdown","source":"### 2. Valida√ß√£o da Classifica√ß√£o\n\nUm passo crucial em qualquer tarefa de classifica√ß√£o √© verificar a qualidade dos resultados. Vamos extrair uma amostra aleat√≥ria de tweets classificados como `reclamacao` e `elogio` para avaliar se nosso classificador simples est√° se comportando como esperado.","metadata":{}},{"cell_type":"code","source":"# --- Valida√ß√£o por Amostragem ---\n\nprint(\"--- Amostra de Tweets classificados como RECLAMA√á√ÉO ---\")\n# Usamos '.tolist()' para obter uma lista de strings, facilitando a exibi√ß√£o.\namostra_reclamacoes = df_filtered[df_filtered['tipo'] == 'reclamacao']['text'].sample(5).tolist()\n\n# O loop 'enumerate' nos d√° um contador 'i' (come√ßando em 1) e o tweet.\nfor i, tweet in enumerate(amostra_reclamacoes, 1):\n    print(f\"{i}: {tweet}\\n\")\n\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\n\nprint(\"--- Amostra de Tweets classificados como ELOGIO ---\")\namostra_elogios = df_filtered[df_filtered['tipo'] == 'elogio']['text'].sample(5).tolist()\nfor i, tweet in enumerate(amostra_elogios, 1):\n    # A corre√ß√£o √© remover as aspas extras no final da linha abaixo.\n    print(f\"{i}: {tweet}\\n\")","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-08-14T15:02:01.853342Z","iopub.execute_input":"2025-08-14T15:02:01.853927Z","iopub.status.idle":"2025-08-14T15:02:02.454283Z","shell.execute_reply.started":"2025-08-14T15:02:01.853896Z","shell.execute_reply":"2025-08-14T15:02:02.453275Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. Refinando a Classifica√ß√£o: Focando Apenas nos Clientes\n\nNossa valida√ß√£o manual revelou um insight importante: o classificador est√° identificando corretamente as palavras-chave, mas est√° sendo aplicado a todos os tweets, incluindo os dos agentes de suporte. Isso gera falsos positivos (e.g., um agente que menciona a palavra \"issue\" tem seu tweet classificado como uma reclama√ß√£o).\n\nPara criar uma feature mais precisa, vamos refinar nossa abordagem: aplicaremos a l√≥gica de classifica√ß√£o **apenas nos tweets de entrada (inbound)**, que s√£o os que v√™m dos clientes.","metadata":{}},{"cell_type":"code","source":"# --- Criando uma Feature de Inten√ß√£o Refinada ---\n\ndef classificar_intencao_cliente(row):\n    \"\"\"\n    Aplica a l√≥gica de classifica√ß√£o apenas se o tweet for de um cliente.\n    Recebe uma linha inteira do DataFrame como entrada.\n    \"\"\"\n    # Se o tweet for inbound (do cliente), aplicamos nossa l√≥gica.\n    if row['inbound']:\n        texto = str(row['text']).lower()\n        palavras_reclamacao = ['not working', 'problem', 'issue', 'broken', \"doesn't work\", 'worst', 'unacceptable', 'fail']\n        palavras_elogio = ['thanks', 'great', 'awesome', 'love', 'excellent', 'perfect', 'thank you', 'kudos']\n        \n        if any(p in texto for p in palavras_reclamacao):\n            return 'reclamacao_cliente'\n        elif '?' in texto:\n            return 'duvida_cliente'\n        elif any(p in texto for p in palavras_elogio):\n            return 'elogio_cliente'\n        else:\n            return 'outro_cliente'\n    # Se o tweet n√£o for inbound (da empresa), simplesmente rotulamos como 'resposta_empresa'.\n    else:\n        return 'resposta_empresa'\n\n# Aplicamos a nova fun√ß√£o ao DataFrame inteiro, linha por linha (axis=1)\ndf_filtered['tipo_refinado'] = df_filtered.apply(classificar_intencao_cliente, axis=1)\n\n# Verificamos a nova distribui√ß√£o\nprint(\"--- Distribui√ß√£o das Inten√ß√µes Refinadas ---\")\nprint(df_filtered['tipo_refinado'].value_counts())","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-08-14T15:02:02.455337Z","iopub.execute_input":"2025-08-14T15:02:02.455601Z","iopub.status.idle":"2025-08-14T15:02:32.250215Z","shell.execute_reply.started":"2025-08-14T15:02:02.455580Z","shell.execute_reply":"2025-08-14T15:02:32.249357Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Parte 4: Engenharia de Features II - An√°lise de Sentimento\n\nA segunda feature crucial que vamos criar √© o **sentimento** de cada tweet. Saber se um cliente est√° feliz, neutro ou insatisfeito √© um contexto poderoso para gerar respostas autom√°ticas adequadas.\n\n| Ferramenta     | Justificativa T√©cnica                                                                                               |\n| :------------- | :------------------------------------------------------------------------------------------------------------------ |\n| **VADER (NLTK)** | Escolhido por ser um modelo de an√°lise de sentimento otimizado para textos curtos de redes sociais, **capaz de interpretar emojis, pontua√ß√£o e a intensidade das palavras (e.g., \"very good!!!\")**. |\n| **Visualiza√ß√µes**| Ser√£o usadas para analisar a distribui√ß√£o geral dos sentimentos e, mais importante, a **correla√ß√£o entre a inten√ß√£o do cliente e o seu sentimento**. |\n| **Integra√ß√£o Futura**| A feature `sentimento` ser√° um input direto para o nosso modelo de LLM, permitindo a gera√ß√£o de respostas contextuais. |","metadata":{}},{"cell_type":"code","source":"# --- 1. Implementa√ß√£o da An√°lise de Sentimentos ---\n\n# Importar as bibliotecas e inicializar as ferramentas\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport nltk\nnltk.download('vader_lexicon')\nanalisador = SentimentIntensityAnalyzer()\n\n# Definir a fun√ß√£o para rotular o sentimento\ndef rotular_sentimento(texto):\n    \"\"\"Analisa um texto e o classifica como 'positivo', 'negativo' ou 'neutro'.\"\"\"\n    scores = analisador.polarity_scores(str(texto))\n    compound_score = scores['compound']\n    if compound_score >= 0.05: return 'positivo'\n    elif compound_score <= -0.05: return 'negativo'\n    else: return 'neutro'\n\n# Aplicar a fun√ß√£o ao DataFrame filtrado, criando a coluna 'sentimento'\n# <<< CORRE√á√ÉO DE CONSIST√äNCIA: Usamos 'df_filtered'.\n# Aplicamos no texto original ('text') para que VADER use emojis e pontua√ß√£o.\ndf_filtered['sentimento'] = df_filtered['text'].apply(rotular_sentimento)\n\n# --- 2. Visualiza√ß√£o da Distribui√ß√£o Geral ---\nplt.figure(figsize=(10, 6))\nax = sns.countplot(x='sentimento', data=df_filtered, order=['positivo', 'neutro', 'negativo'], palette='coolwarm_r')\nax.set_title('Distribui√ß√£o Geral dos Sentimentos nos Tweets', fontsize=16)\nax.set_xlabel('Sentimento', fontsize=12)\nax.set_ylabel('Quantidade de Tweets', fontsize=12)\n\n# Adicionar r√≥tulos de dados para clareza\nfor p in ax.patches:\n    ax.annotate(f'{int(p.get_height()):,}', (p.get_x() + p.get_width() / 2., p.get_height()), \n                ha='center', va='center', xytext=(0, 9), textcoords='offset points')\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T15:02:32.251176Z","iopub.execute_input":"2025-08-14T15:02:32.251431Z","iopub.status.idle":"2025-08-14T15:12:21.363737Z","shell.execute_reply.started":"2025-08-14T15:02:32.251411Z","shell.execute_reply":"2025-08-14T15:12:21.362814Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cruzar tipo de mensagem x sentimento\nimport pandas as pd\n\ndf_clientes = df_filtered[df_filtered['inbound'] == True]\ntabela_cruzada = pd.crosstab(df_clientes['tipo_refinado'], df_clientes['sentimento'], normalize='index') * 100\ntabela_cruzada = tabela_cruzada.round(1)\n\n\n# Visualizar com gr√°fico de barras empilhadas\ntabela_cruzada.plot(kind='bar', stacked=True, figsize=(10,6), colormap='coolwarm')\nplt.title('Sentimentos por Tipo de Mensagem (%)')\nplt.xlabel('Tipo de Mensagem')\nplt.ylabel('Porcentagem')\nplt.legend(title='Sentimento')\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T15:12:21.366567Z","iopub.execute_input":"2025-08-14T15:12:21.366823Z","iopub.status.idle":"2025-08-14T15:12:22.275593Z","shell.execute_reply.started":"2025-08-14T15:12:21.366803Z","shell.execute_reply":"2025-08-14T15:12:22.274671Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Insights da An√°lise de Sentimentos\n\nAs visualiza√ß√µes acima nos fornecem uma compreens√£o profunda do tom emocional das intera√ß√µes no nosso dataset.\n\n#### 1. Distribui√ß√£o Geral dos Sentimentos\n\nO primeiro gr√°fico (distribui√ß√£o geral) revela um panorama interessante:\n*   **Predomin√¢ncia Positiva:** A maioria dos tweets no dataset tem um sentimento **positivo**. Isso pode ser um pouco contraintuitivo, j√° que muitas vezes associamos o suporte ao cliente a problemas.\n*   **Volume Relevante de Negatividade:** Apesar da predomin√¢ncia positiva, existe um volume substancial de quase **660 mil tweets negativos**, o que representa uma enorme quantidade de clientes insatisfeitos que precisam de aten√ß√£o.\n\nEssa vis√£o geral, no entanto, √© incompleta. Ela mistura tweets de clientes com respostas de empresas. A verdadeira an√°lise vem do cruzamento com a inten√ß√£o do cliente.\n\n#### 2. Correla√ß√£o entre Inten√ß√£o do Cliente e Sentimento\n\nO segundo gr√°fico (barras empilhadas) √© a an√°lise mais poderosa e valida nossas hip√≥teses:\n*   **Reclama√ß√µes s√£o Negativas:** Como esperado, a categoria `reclamacao_cliente` √© majoritariamente composta por sentimentos **negativos** (cerca de 55%). Isso confirma que nosso classificador de inten√ß√£o est√° funcionando bem.\n*   **Elogios s√£o Positivos:** De forma esmagadora, a categoria `elogio_cliente` √© quase **100% positiva**. Outra forte valida√ß√£o da nossa engenharia de features.\n*   **D√∫vidas e Outros:** As categorias `duvida_cliente` e `outro_cliente` s√£o mais mistas, com uma distribui√ß√£o mais equilibrada entre sentimentos positivos, neutros e negativos. Isso faz sentido, pois uma d√∫vida pode ser formulada de maneira neutra (\"como fa√ßo X?\"), frustrada (\"por que n√£o consigo fazer X?!\") ou positiva.\n\n**Conclus√£o Estrat√©gica:**\nConseguimos criar duas features (`tipo_refinado` e `sentimento`) que n√£o apenas estruturam os dados, mas tamb√©m se validam mutuamente. Agora temos um contexto rico para cada tweet de cliente, o que ser√° fundamental para a pr√≥xima e √∫ltima etapa do projeto: **treinar um modelo de IA para gerar respostas adequadas a cada cen√°rio**.","metadata":{}},{"cell_type":"markdown","source":"### An√°lise B√¥nus: Ranking de Sentimento por Empresa\n\nComo uma an√°lise de neg√≥cio adicional, podemos calcular o sentimento m√©dio associado √†s **respostas** de cada empresa. Isso nos permite criar um ranking e identificar quais marcas se comunicam de forma mais positiva ou negativa.","metadata":{}},{"cell_type":"code","source":"# --- Ranking de Sentimento M√©dio por Empresa ---\n\n# 1. Criar a coluna com a pontua√ß√£o 'compound' bruta no nosso DataFrame principal.\ndf_filtered['compound_score'] = df_filtered['text'].apply(lambda text: analisador.polarity_scores(str(text))['compound'])\n\n# 2. Filtrar apenas as respostas das empresas ('outbound') e calcular a m√©dia do score.\nsentimento_por_empresa = df_filtered[df_filtered['inbound'] == False].groupby('author_id')['compound_score'].mean().sort_values(ascending=False)\n\n# 3. Visualizar as 10 empresas com as respostas mais positivas.\nplt.figure(figsize=(12, 6))\nsentimento_por_empresa.head(10).plot(kind='barh', color='green')\nplt.title('Top 10 Empresas com Maior Sentimento M√©dio em suas Respostas', fontsize=16)\nplt.xlabel('Sentimento M√©dio (Compound Score)', fontsize=12)\nplt.ylabel('ID da Empresa', fontsize=12)\nplt.gca().invert_yaxis()\nplt.show()\n\n# 4. Visualizar as 10 empresas com as respostas mais negativas.\nplt.figure(figsize=(12, 6))\nsentimento_por_empresa.tail(10).plot(kind='barh', color='red')\nplt.title('Top 10 Empresas com Menor Sentimento M√©dio em suas Respostas', fontsize=16)\nplt.xlabel('Sentimento M√©dio (Compound Score)', fontsize=12)\nplt.ylabel('ID da Empresa', fontsize=12)\nplt.gca().invert_yaxis()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T15:12:22.276606Z","iopub.execute_input":"2025-08-14T15:12:22.276926Z","iopub.status.idle":"2025-08-14T15:22:18.805027Z","shell.execute_reply.started":"2025-08-14T15:12:22.276901Z","shell.execute_reply":"2025-08-14T15:22:18.804115Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Mapa de Calor: Correla√ß√£o entre Inten√ß√£o e Sentimento\n\nAgora, vamos conectar nossas duas novas features (`tipo_refinado` e `sentimento`). Qual √© o sentimento predominante em cada tipo de inten√ß√£o do cliente? Esta an√°lise √© fundamental para validar nossas classifica√ß√µes.","metadata":{}},{"cell_type":"code","source":"# --- Mapa de Calor: Correla√ß√£o entre Inten√ß√£o e Sentimento ---\n\n# 1. Filtrar apenas os tweets que s√£o de clientes ('inbound').\ndf_clientes = df_filtered[df_filtered['inbound'] == True].copy()\n\n# 2. Criar uma tabela cruzada (crosstab) usando nossa coluna 'tipo_refinado'.\n#    <<< CORRE√á√ÉO PRINCIPAL AQUI >>>\ncross_tab = pd.crosstab(index=df_clientes['tipo_refinado'], \n                        columns=df_clientes['sentimento'],\n                        normalize=\"index\") * 100\n\n# 3. Gerar o Mapa de Calor (Heatmap) para uma visualiza√ß√£o impactante.\nplt.figure(figsize=(12, 7))\nsns.heatmap(cross_tab, annot=True, cmap='viridis', fmt='.1f',\n            cbar_kws={'label': 'Porcentagem (%)'})\nplt.title('Mapa de Calor: Sentimento (%) por Tipo de Inten√ß√£o do Cliente', fontsize=16)\nplt.xlabel('Sentimento', fontsize=12)\nplt.ylabel('Tipo de Inten√ß√£o (Cliente)', fontsize=12)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T15:22:18.805926Z","iopub.execute_input":"2025-08-14T15:22:18.806198Z","iopub.status.idle":"2025-08-14T15:22:20.529949Z","shell.execute_reply.started":"2025-08-14T15:22:18.806177Z","shell.execute_reply":"2025-08-14T15:22:20.529081Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### An√°lise de Performance por Marca e Valida√ß√£o Cruzada\n\nAs an√°lises finais desta se√ß√£o nos permitem avaliar a performance de comunica√ß√£o das empresas e validar a coer√™ncia das nossas features.\n\n#### 1. Ranking de Sentimento por Empresa\n\nOs gr√°ficos de barras horizontais nos mostram um ranking claro de quais empresas utilizam uma linguagem mais positiva ou negativa em suas respostas de suporte.\n*   **Melhores Comunicadores:** Empresas como **HPSupport** e **TwitterSupport** se destacam por usarem uma linguagem consistentemente positiva em suas intera√ß√µes.\n*   **Pontos de Melhoria:** Marcas como **KFC_UKI_Help** e **SW_Help** apresentam um sentimento m√©dio negativo em suas respostas, o que pode indicar um tom mais seco, rob√≥tico ou at√© mesmo frustrado, sendo um ponto de aten√ß√£o para a gest√£o de marca.\n\nEsta an√°lise poderia, em um cen√°rio de neg√≥cio real, ser usada para identificar benchmarks de comunica√ß√£o ou √°reas que necessitam de treinamento.\n\n#### 2. Mapa de Calor: A Prova Final\n\nO mapa de calor √© a valida√ß√£o definitiva da nossa engenharia de features. Ele mostra a distribui√ß√£o percentual de sentimentos dentro de cada tipo de inten√ß√£o do cliente, revelando padr√µes claros:\n*   **Elogios s√£o Positivos (90.4%):** Como esperado, a vasta maioria dos elogios de clientes tem um sentimento detectado como positivo.\n*   **Reclama√ß√µes s√£o Negativas (55.4%):** A categoria `reclamacao_cliente` √© predominantemente negativa. Isso n√£o s√≥ valida nosso classificador de inten√ß√£o, mas tamb√©m mostra que a an√°lise de sentimentos est√° capturando a frustra√ß√£o dos clientes. O fato de n√£o ser 100% negativo √© interessante, indicando que algumas reclama√ß√µes s√£o feitas de forma mais neutra ou at√© educada (\"... aprecio a ajuda, mas ainda n√£o funcionou\").\n*   **D√∫vidas e Outros:** As outras categorias s√£o mais distribu√≠das, o que √© esperado, pois perguntas e coment√°rios gerais podem ser feitos em qualquer tom.\n\n**Conclus√£o Final da Engenharia de Features:**\nCom sucesso, transformamos textos brutos e n√£o estruturados em **duas features de alta qualidade e mutuamente validadas**: `tipo_refinado` (a inten√ß√£o do cliente) e `sentimento` (o tom emocional).\n\nEstamos agora na melhor posi√ß√£o poss√≠vel para avan√ßar para a fase final e mais empolgante do projeto: **utilizar essas features para guiar um modelo de IA Generativa na etapa de Modelagem**.\n","metadata":{}},{"cell_type":"markdown","source":"# Parte 2: Modelagem - Gera√ß√£o de Respostas com LLM\n\nCom nossas features de contexto (`tipo_refinado` e `sentimento`) prontas, entramos na fase de modelagem. O objetivo aqui √© construir um sistema que utilize um **Modelo de Linguagem Grande (LLM)** para gerar respostas de atendimento ao cliente que sejam n√£o apenas relevantes, mas tamb√©m contextualmente adequadas ao tom e √† inten√ß√£o de cada tweet.\n\n### 1. Escolha da Ferramenta e do Modelo\n\n| Tecnologia | Justificativa T√©cnica                                                                                                                                                                     |\n| :----------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **`transformers` (Hugging Face)** | √â a biblioteca padr√£o da ind√∫stria para trabalhar com modelos de linguagem de √∫ltima gera√ß√£o. Ela nos d√° acesso a milhares de modelos pr√©-treinados e ferramentas para control√°-los. |\n| **`gpt2`** | Ap√≥s experimenta√ß√£o inicial com modelos de di√°logo (`DialoGPT`), escolhemos o `gpt2` como nosso modelo final. Por ser um modelo de prop√≥sito geral, ele demonstrou maior flexibilidade para seguir os padr√µes e instru√ß√µes complexas do nosso prompt, resultando em respostas de maior qualidade para esta tarefa. |\n---\n\n### üß† Um Mergulho R√°pido nos Transformers: O Que Roda Por Baixo dos Panos?\n\nEmbora a biblioteca `transformers` facilite nosso trabalho com uma √∫nica chamada de `pipeline`, por tr√°s dela ocorre um processo sofisticado, baseado na revolucion√°ria arquitetura \"Transformer\". Entender seus fundamentos nos permite criar prompts melhores e depurar problemas de forma mais eficaz.\n\nAqui est√° uma vis√£o simplificada do que acontece quando pedimos para a nossa IA gerar uma resposta:\n\n1.  **Tokeniza√ß√£o:** O texto de entrada (nosso \"prompt\") n√£o √© lido diretamente. Primeiro, ele √© quebrado em peda√ßos menores chamados **tokens**. Estes podem ser palavras inteiras (como \"app\"), partes de palavras (como \"un-accept-able\") ou pontua√ß√£o.\n\n2.  **Embeddings (Convers√£o para Vetores):** Cada token √© ent√£o mapeado para um **vetor num√©rico** de alta dimens√£o. Este vetor, chamado de *embedding*, representa o \"significado\" do token em um espa√ßo matem√°tico. Palavras com significados semelhantes ter√£o vetores pr√≥ximos.\n\n3.  **O Mecanismo de Auto-Aten√ß√£o (Self-Attention):** Este √© o ingrediente secreto e a grande inova√ß√£o da arquitetura Transformer. Antes de gerar uma resposta, o modelo precisa entender o **contexto**. O mecanismo de aten√ß√£o permite que o modelo pese a import√¢ncia de cada token na frase em rela√ß√£o a todos os outros.\n    *   **Analogia:** Imagine que voc√™ est√° lendo a frase: *\"O aplicativo parou de funcionar depois da atualiza√ß√£o, que decep√ß√£o!\"*. Para entender a frustra√ß√£o, o modelo precisa dar mais \"aten√ß√£o\" √†s palavras **'parou'**, **'funcionar'**, **'atualiza√ß√£o'** e **'decep√ß√£o'** do que a 'O' ou 'de'. O mecanismo de aten√ß√£o essencialmente \"ilumina\" as palavras mais relevantes para o contexto, permitindo que o modelo \"preste aten√ß√£o\" ao que realmente importa.\n\n4.  **Gera√ß√£o da Resposta (Processo Autoregressivo):** Com o contexto entendido, o modelo come√ßa a gerar a resposta, um token de cada vez. Ele prev√™ a palavra mais prov√°vel para vir a seguir. Essa nova palavra √© ent√£o adicionada √† sequ√™ncia, e o processo se repete, com o modelo prestando aten√ß√£o em toda a sequ√™ncia (prompt original + palavras j√° geradas) para prever a pr√≥xima palavra, e assim por diante.\n\n5.  **Decodifica√ß√£o:** Finalmente, a sequ√™ncia de tokens gerada pela IA √© decodificada de volta para um **texto leg√≠vel**, que √© o que vemos como a resposta final.\n\nEntender esse fluxo nos ajuda a compreender por que o \"prompt engineering\" e t√©cnicas como o \"Few-Shot Prompting\" s√£o t√£o eficazes: estamos, na verdade, fornecendo um contexto inicial muito mais rico para o mecanismo de aten√ß√£o operar.","metadata":{}},{"cell_type":"code","source":"# --- Carregando o Modelo Final: GPT-2 ---\n\n# Importar as bibliotecas necess√°rias\nfrom transformers import pipeline\nimport torch\n\n# Carregar o pipeline com o modelo 'gpt2', que √© mais robusto para seguir instru√ß√µes.\nprint(\"Carregando o modelo de IA 'gpt2'...\")\ngenerator = pipeline('text-generation', model='gpt2', device=0 if torch.cuda.is_available() else -1)\nprint(\"\\nModelo de IA carregado com sucesso!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T16:27:24.053412Z","iopub.execute_input":"2025-08-14T16:27:24.054553Z","iopub.status.idle":"2025-08-14T16:27:30.517961Z","shell.execute_reply.started":"2025-08-14T16:27:24.054522Z","shell.execute_reply":"2025-08-14T16:27:30.517119Z"},"_kg_hide-input":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2. Construindo o C√©rebro da Solu√ß√£o: A Fun√ß√£o de Gera√ß√£o Contextual\n\nEsta fun√ß√£o representa o cora√ß√£o do sistema. Em vez de simplesmente passar o tweet do cliente para o modelo, foi constru√≠do um **prompt din√¢mico** para instru√≠-lo sobre como se comportar.\n\nAp√≥s um processo de experimenta√ß√£o, concluiu-se que a t√©cnica mais eficaz para o modelo `gpt2` nesta tarefa √© o **\"One-Shot Prompting\"**. A abordagem consiste em fornecer ao modelo um √∫nico exemplo de alta qualidade de uma intera√ß√£o ideal (Cliente -> Agente).\n\nIsso \"mostra\" ao modelo o tom, o formato e a qualidade da resposta esperada, for√ßando-o a seguir um padr√£o conversacional e, consequentemente, a gerar resultados muito mais consistentes do que apenas atrav√©s de instru√ß√µes diretas.","metadata":{}},{"cell_type":"code","source":"# --- Fun√ß√£o de Gera√ß√£o Final (com Prompt H√≠brido \"One-Shot\") ---\n\ndef gerar_resposta_final(tweet_texto):\n    \"\"\"\n    Gera uma resposta usando um prompt h√≠brido que d√° um exemplo claro (One-Shot),\n    uma t√©cnica muito eficaz para modelos como o GPT-2.\n    \"\"\"\n    # Este prompt define o contexto e mostra um exemplo ideal de intera√ß√£o.\n    prompt = f\"\"\"This is a transcript of a customer service chat.\n\n###\nCustomer: My order hasn't arrived yet and the tracking number doesn't work!\nAgent: I'm so sorry to hear about the trouble with your order. I can definitely look into this for you. Could you please provide your order number?\n###\nCustomer: {tweet_texto}\nAgent: We're sorry\"\"\"\n    \n    respostas = generator(\n        prompt,\n        max_new_tokens=60,      # Limita o tamanho da resposta\n        no_repeat_ngram_size=2, # Evita repeti√ß√µes\n        pad_token_id=generator.tokenizer.eos_token_id,\n        truncation=True\n    )\n\n    # L√≥gica de limpeza para extrair apenas a resposta final do agente.\n    texto_gerado = respostas[0]['generated_text']\n    # Encontra a posi√ß√£o da √∫ltima ocorr√™ncia de \"Agent:\"\n    posicao_final_agent = texto_gerado.rfind(\"Agent:\")\n    # Pega todo o texto ap√≥s essa posi√ß√£o.\n    resposta_limpa = texto_gerado[posicao_final_agent + len(\"Agent:\"):].strip()\n    \n    return resposta_limpa\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T16:36:41.919898Z","iopub.execute_input":"2025-08-14T16:36:41.920878Z","iopub.status.idle":"2025-08-14T16:36:41.927259Z","shell.execute_reply.started":"2025-08-14T16:36:41.920845Z","shell.execute_reply":"2025-08-14T16:36:41.926268Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3. Teste em Cen√°rios Reais\n\nPara validar o sistema completo, a etapa seguinte consiste em test√°-lo com dados reais. Ser√£o selecionadas amostras aleat√≥rias de diferentes inten√ß√µes de cliente (reclama√ß√µes, elogios, etc.) do dataset para serem processadas pela fun√ß√£o de gera√ß√£o de IA, permitindo uma avalia√ß√£o qualitativa das respostas geradas.","metadata":{}},{"cell_type":"code","source":"# --- Teste Final com a Abordagem Definitiva ---\n\n# --- Teste 1: Uma Reclama√ß√£o REAL de um cliente ---\nexemplo_reclamacao = df_filtered[df_filtered['tipo_refinado'] == 'reclamacao_cliente'].sample(1)\ntexto_reclamacao = exemplo_reclamacao['text'].values[0]\nresposta_gerada_reclamacao = gerar_resposta_final(texto_reclamacao)\n\nprint(\"--- üí¨ EXEMPLO COM RECLAMA√á√ÉO ---\")\nprint(f\"Tweet Original: {texto_reclamacao}\")\nprint(f\"‚úÖ Resposta Gerada pelo LLM: {resposta_gerada_reclamacao}\\n\")\n\n\n# --- Teste 2: Um Elogio REAL de um cliente ---\nexemplo_elogio = df_filtered[df_filtered['tipo_refinado'] == 'elogio_cliente'].sample(1)\ntexto_elogio = exemplo_elogio['text'].values[0]\nresposta_gerada_elogio = gerar_resposta_final(texto_elogio)\n\nprint(\"--- üòç EXEMPLO COM ELOGIO ---\")\nprint(f\"Tweet Original: {texto_elogio}\")\nprint(f\"‚úÖ Resposta Gerada pelo LLM: {resposta_gerada_elogio}\\n\")\n\n\n# --- Teste 3: Uma D√∫vida REAL de um cliente ---\nexemplo_duvida = df_filtered[df_filtered['tipo_refinado'] == 'duvida_cliente'].sample(1)\ntexto_duvida = exemplo_duvida['text'].values[0]\nresposta_gerada_duvida = gerar_resposta_final(texto_duvida)\n\nprint(\"--- ‚ùì EXEMPLO COM D√öVIDA ---\")\nprint(f\"Tweet Original: {texto_duvida}\")\nprint(f\"‚úÖ Resposta Gerada pelo LLM: {resposta_gerada_duvida}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-14T16:36:44.772398Z","iopub.execute_input":"2025-08-14T16:36:44.772734Z","iopub.status.idle":"2025-08-14T16:36:52.053837Z","shell.execute_reply.started":"2025-08-14T16:36:44.772709Z","shell.execute_reply":"2025-08-14T16:36:52.052920Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclus√£o e Pr√≥ximos Passos\n\n## ‚úÖ Resultados e Conclus√£o do Projeto\n\nNeste projeto, foi desenvolvido com sucesso um prot√≥tipo de ponta a ponta para um sistema de otimiza√ß√£o de atendimento ao cliente baseado em IA. Partindo de um dataset bruto de quase 3 milh√µes de tweets, foi poss√≠vel:\n\n1.  **Analisar e Pr√©-processar** os dados, identificando o per√≠odo de maior relev√¢ncia (2017) e aplicando t√©cnicas de limpeza de texto.\n2.  **Criar Features de Alto Valor** atrav√©s da Engenharia de Features, classificando a inten√ß√£o de cada tweet de cliente (`tipo_refinado`) e seu tom emocional (`sentimento`).\n3.  **Implementar um Modelo de Linguagem Avan√ßado (LLM)**, o **`gpt2`**, para gerar respostas contextuais.\n4.  **Refinar a Gera√ß√£o de Respostas** utilizando a t√©cnica de **\"One-Shot Prompting\"** e o controle de par√¢metros (`temperature`, `top_k`, etc.), melhorando significativamente a qualidade e a consist√™ncia das respostas geradas.\n\nO resultado final √© um sistema capaz de receber um tweet e, em segundos, fornecer uma sugest√£o de resposta adequada, demonstrando o imenso potencial da IA Generativa para automatizar e escalar opera√ß√µes de atendimento ao cliente.\n\n## üöÄ Pr√≥ximos Passos e Melhorias Futuras\n\nEste prot√≥tipo funcional √© um excelente ponto de partida, mas um projeto de IA est√° sempre em evolu√ß√£o. Com base no que foi constru√≠do, identifico v√°rias oportunidades claras para levar esta solu√ß√£o ao pr√≥ximo n√≠vel:\n\n*   **Evoluir a Classifica√ß√£o de Inten√ß√£o:** O classificador por regras foi um √≥timo primeiro passo, mas para capturar nuances mais complexas, o pr√≥ximo passo seria **treinar um modelo de Machine Learning dedicado**. Eu poderia come√ßar com um `Logistic Regression` sobre vetores TF-IDF e, para m√°xima precis√£o, evoluir para um modelo baseado em Transformers, como o `BERT`, que treinaria especificamente para esta tarefa.\n\n*   **Personalizar o Tom com Fine-tuning:** Para que as respostas soem exatamente como uma marca espec√≠fica, eu realizaria o **fine-tuning (ajuste fino) do modelo `gpt2`**. Para isso, eu buscaria um dataset com exemplos reais de intera√ß√µes da empresa, ensinando o modelo a adotar um tom de voz e um estilo de comunica√ß√£o √∫nicos.\n\n*   **Aumentar a Qualidade com Modelos de Ponta:** Para alcan√ßar o estado da arte em gera√ß√£o de texto, o passo seguinte seria integrar o sistema com APIs de modelos maiores, como o **GPT-4 (OpenAI)** ou o **Gemini (Google AI)**. Isso me permitiria explorar como a qualidade da resposta escala com o poder do modelo e me daria experi√™ncia pr√°tica com plataformas de MLaaS (Machine Learning as a Service) como **AWS Bedrock** ou **Azure AI Studio**.\n\n*   **Transformar em Produto com um Dashboard Interativo:** A melhor forma de demonstrar o valor deste projeto √© torn√°-lo tang√≠vel. Meu pr√≥ximo objetivo √© **empacotar esta solu√ß√£o em um dashboard interativo usando Streamlit**. Isso permitiria que qualquer pessoa, mesmo sem conhecimento t√©cnico, pudesse testar a IA, ver os resultados e entender seu potencial.\n\n*   **Quantificar o Impacto de Neg√≥cio:** Finalmente, em um contexto corporativo, eu focaria em uma **an√°lise de custo-benef√≠cio**. Isso envolveria estimar o impacto da automa√ß√£o em m√©tricas de neg√≥cio, como a potencial redu√ß√£o no Tempo M√©dio de Resposta (TMR) e o c√°lculo do Retorno Sobre o Investimento (ROI) da solu√ß√£o.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}